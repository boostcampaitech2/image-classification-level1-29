{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "about-heavy",
   "metadata": {},
   "source": [
    "## 0. Libarary 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cubic-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize\n",
    "from torchvision.models import resnet50, resnext50_32x4d, resnet18, resnext101_32x8d\n",
    "import timm\n",
    "import albumentations as A\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch_optimizer as optim\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "from catalyst.data import BalanceClassSampler\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0a315e-6d3c-4fae-8a56-26704e4a6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77238f9-9fa5-45fa-97c9-68cd3724be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e170d98a-18e5-4a7f-91eb-575469d09378",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03128f-f827-4668-b213-8ae16d0f08f7",
   "metadata": {},
   "source": [
    "### (1) Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc6a210-a832-4bd7-b68f-466aa2761d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터셋 폴더 경로를 지정해주세요.\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "trainimage_dir = os.path.join(train_dir, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c412b27-edf7-446e-b965-40a7ffc154d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path\n",
       "0     000001  female  Asian   45  000001_female_Asian_45\n",
       "1     000002  female  Asian   52  000002_female_Asian_52\n",
       "2     000004    male  Asian   54    000004_male_Asian_54\n",
       "3     000005  female  Asian   58  000005_female_Asian_58\n",
       "4     000006  female  Asian   59  000006_female_Asian_59\n",
       "...      ...     ...    ...  ...                     ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "train_df = pd.read_csv(os.path.join(train_dir, 'train.csv'))\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87297828-b7a3-421b-9812-59a0abed5f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>mask</th>\n",
       "      <th>wear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask1</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask2</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask3</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask4</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask5</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>mask3</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>mask4</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>mask5</td>\n",
       "      <td>Wear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>incorrect_mask</td>\n",
       "      <td>Incorrect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>normal</td>\n",
       "      <td>Not Wear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender   race   age                    path            mask  \\\n",
       "0      000001  female  Asian  45.0  000001_female_Asian_45           mask1   \n",
       "1      000001  female  Asian  45.0  000001_female_Asian_45           mask2   \n",
       "2      000001  female  Asian  45.0  000001_female_Asian_45           mask3   \n",
       "3      000001  female  Asian  45.0  000001_female_Asian_45           mask4   \n",
       "4      000001  female  Asian  45.0  000001_female_Asian_45           mask5   \n",
       "...       ...     ...    ...   ...                     ...             ...   \n",
       "18895  006959    male  Asian  19.0    006959_male_Asian_19           mask3   \n",
       "18896  006959    male  Asian  19.0    006959_male_Asian_19           mask4   \n",
       "18897  006959    male  Asian  19.0    006959_male_Asian_19           mask5   \n",
       "18898  006959    male  Asian  19.0    006959_male_Asian_19  incorrect_mask   \n",
       "18899  006959    male  Asian  19.0    006959_male_Asian_19          normal   \n",
       "\n",
       "            wear  \n",
       "0           Wear  \n",
       "1           Wear  \n",
       "2           Wear  \n",
       "3           Wear  \n",
       "4           Wear  \n",
       "...          ...  \n",
       "18895       Wear  \n",
       "18896       Wear  \n",
       "18897       Wear  \n",
       "18898  Incorrect  \n",
       "18899   Not Wear  \n",
       "\n",
       "[18900 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = ['mask1', 'mask2', 'mask3', 'mask4', 'mask5', 'incorrect_mask', 'normal']\n",
    "wears = ['Wear', 'Wear', 'Wear', 'Wear', 'Wear', 'Incorrect', 'Not Wear']\n",
    "mask_df = pd.DataFrame()\n",
    "for person in train_df.values:\n",
    "    for mask, wear in zip(masks, wears):\n",
    "        mask_df = mask_df.append(pd.Series(np.append(person, (mask, wear))), ignore_index=True)\n",
    "mask_df.columns = np.append(train_df.columns.values, ('mask', 'wear'))\n",
    "mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e94ec1-2d04-4170-8847-ca7baff2a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_df = mask_df.sample(frac=1).reset_index(drop=True)\n",
    "#mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5a057fc-08f4-45d7-9bca-2914fb413e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "      <th>mask</th>\n",
       "      <th>wear</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask1</td>\n",
       "      <td>Wear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask2</td>\n",
       "      <td>Wear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask3</td>\n",
       "      <td>Wear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask4</td>\n",
       "      <td>Wear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45.0</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "      <td>mask5</td>\n",
       "      <td>Wear</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>mask3</td>\n",
       "      <td>Wear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>mask4</td>\n",
       "      <td>Wear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>mask5</td>\n",
       "      <td>Wear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>incorrect_mask</td>\n",
       "      <td>Incorrect</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19.0</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "      <td>normal</td>\n",
       "      <td>Not Wear</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender   race   age                    path            mask  \\\n",
       "0      000001  female  Asian  45.0  000001_female_Asian_45           mask1   \n",
       "1      000001  female  Asian  45.0  000001_female_Asian_45           mask2   \n",
       "2      000001  female  Asian  45.0  000001_female_Asian_45           mask3   \n",
       "3      000001  female  Asian  45.0  000001_female_Asian_45           mask4   \n",
       "4      000001  female  Asian  45.0  000001_female_Asian_45           mask5   \n",
       "...       ...     ...    ...   ...                     ...             ...   \n",
       "18895  006959    male  Asian  19.0    006959_male_Asian_19           mask3   \n",
       "18896  006959    male  Asian  19.0    006959_male_Asian_19           mask4   \n",
       "18897  006959    male  Asian  19.0    006959_male_Asian_19           mask5   \n",
       "18898  006959    male  Asian  19.0    006959_male_Asian_19  incorrect_mask   \n",
       "18899  006959    male  Asian  19.0    006959_male_Asian_19          normal   \n",
       "\n",
       "            wear  label  \n",
       "0           Wear      4  \n",
       "1           Wear      4  \n",
       "2           Wear      4  \n",
       "3           Wear      4  \n",
       "4           Wear      4  \n",
       "...          ...    ...  \n",
       "18895       Wear      0  \n",
       "18896       Wear      0  \n",
       "18897       Wear      0  \n",
       "18898  Incorrect      6  \n",
       "18899   Not Wear     12  \n",
       "\n",
       "[18900 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df = pd.DataFrame()\n",
    "for idx, person in mask_df.iterrows():\n",
    "    gender = person['gender']\n",
    "    gender = 0 if gender=='male' else 1\n",
    "\n",
    "    age = person['age']\n",
    "    if age >= 60.0:\n",
    "        age = 2\n",
    "    elif age >= 30.0:\n",
    "        age = 1\n",
    "    else:\n",
    "        age = 0\n",
    "\n",
    "    mask = person['wear']\n",
    "    if mask == 'Wear':\n",
    "        mask = 0\n",
    "    elif mask == 'Incorrect':\n",
    "        mask = 1\n",
    "    else:\n",
    "        mask = 2\n",
    "\n",
    "    label = 6*mask + 3*gender + age\n",
    "    labeled_df = labeled_df.append(pd.Series(np.append(person, label)), ignore_index=True)\n",
    "labeled_df.columns = np.append(mask_df.columns.values, 'label')\n",
    "labeled_df = labeled_df.astype({'label': int})\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c56debf3-50ef-4d40-8c80-831cfc855dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c639b38-03dd-487a-8e7f-61d538349675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, path, labeled_df, transform):\n",
    "        super(TrainDataset).__init__()\n",
    "        self.path = path\n",
    "        self.labeled_df = labeled_df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        full_path = os.path.join(self.path, self.labeled_df.iloc[idx]['path'])\n",
    "        img_list = glob.glob(full_path + '/*')\n",
    "        file_name = self.labeled_df.iloc[idx]['mask']\n",
    "        try:\n",
    "            image = Image.open(os.path.join(full_path, file_name+'.jpg'))\n",
    "        except:\n",
    "            try:\n",
    "                image = Image.open(os.path.join(full_path, file_name+'.png'))\n",
    "            except:\n",
    "                image = Image.open(os.path.join(full_path, file_name+'.jpeg'))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labeled_df.iloc[idx]['label']\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labeled_df)\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.labeled_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acc18ba-d777-47d7-92c4-12aeb62c9a7c",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ffc9345-3bce-47e3-ac79-fe34046e753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0015\n",
    "betas = (0.9, 0.999)\n",
    "weight_decay = 1e-4\n",
    "T_max = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "062a0a93-08c3-4a5f-b6b8-9fd1bc8cccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ---------------------- Fold 1 --------------------------------------------\n",
      " ====================== epoch 1 ======================\n",
      "Iteration   0 | Train Loss  3.7969 | Classifier Accuracy 9.38\n",
      "Iteration  50 | Train Loss  0.8068 | Classifier Accuracy 71.88\n",
      "Iteration 100 | Train Loss  0.8464 | Classifier Accuracy 75.00\n",
      "Iteration 150 | Train Loss  0.3855 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.3015 | Classifier Accuracy 87.50\n",
      "Iteration 250 | Train Loss  0.1152 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.4511 | Classifier Accuracy 84.38\n",
      "Iteration 350 | Train Loss  0.4484 | Classifier Accuracy 90.62\n",
      "Iteration 400 | Train Loss  0.2351 | Classifier Accuracy 90.62\n",
      "Iteration 450 | Train Loss  0.0795 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 17 s\n",
      "Train Loss Mean 0.6367 | Accuracy 80.58 | F1-Score 0.6841\n",
      "Valid Loss Mean 0.7029 | Accuracy 81.85 | F1-Score 0.6858\n",
      "\n",
      " ====================== epoch 2 ======================\n",
      "Iteration   0 | Train Loss  0.0361 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.4053 | Classifier Accuracy 90.62\n",
      "Iteration 100 | Train Loss  0.2663 | Classifier Accuracy 90.62\n",
      "Iteration 150 | Train Loss  0.1343 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.2972 | Classifier Accuracy 90.62\n",
      "Iteration 250 | Train Loss  0.5614 | Classifier Accuracy 87.50\n",
      "Iteration 300 | Train Loss  0.0880 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.1766 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.1179 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.1518 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1915 | Accuracy 93.66 | F1-Score 0.8725\n",
      "Valid Loss Mean 0.7648 | Accuracy 77.94 | F1-Score 0.6641\n",
      "\n",
      " ====================== epoch 3 ======================\n",
      "Iteration   0 | Train Loss  0.1198 | Classifier Accuracy 90.62\n",
      "Iteration  50 | Train Loss  0.0197 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.1613 | Classifier Accuracy 93.75\n",
      "Iteration 150 | Train Loss  0.0652 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.1481 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.3712 | Classifier Accuracy 84.38\n",
      "Iteration 300 | Train Loss  0.4754 | Classifier Accuracy 87.50\n",
      "Iteration 350 | Train Loss  0.1911 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.0128 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.3810 | Classifier Accuracy 87.50\n",
      "\n",
      "[Summary] Elapsed time : 1 m 23 s\n",
      "Train Loss Mean 0.1355 | Accuracy 95.57 | F1-Score 0.9134\n",
      "Valid Loss Mean 0.6686 | Accuracy 85.37 | F1-Score 0.7250\n",
      "\n",
      " ====================== epoch 4 ======================\n",
      "Iteration   0 | Train Loss  0.0181 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.3744 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0454 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0421 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0430 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0409 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.1044 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.0974 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.0262 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0356 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1160 | Accuracy 96.45 | F1-Score 0.9331\n",
      "Valid Loss Mean 1.0054 | Accuracy 77.78 | F1-Score 0.6649\n",
      "\n",
      " ====================== epoch 5 ======================\n",
      "Iteration   0 | Train Loss  0.0668 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.2606 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0589 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0557 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0264 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0370 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.2227 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0112 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.3344 | Classifier Accuracy 90.62\n",
      "Iteration 450 | Train Loss  0.0208 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1154 | Accuracy 96.37 | F1-Score 0.9296\n",
      "Valid Loss Mean 0.7969 | Accuracy 82.17 | F1-Score 0.7153\n",
      "\n",
      " ====================== epoch 6 ======================\n",
      "Iteration   0 | Train Loss  0.0264 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0237 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0548 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0235 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.1692 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.2711 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0050 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0267 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0488 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0538 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0813 | Accuracy 97.44 | F1-Score 0.9428\n",
      "Valid Loss Mean 0.8354 | Accuracy 81.78 | F1-Score 0.7030\n",
      "\n",
      " ====================== epoch 7 ======================\n",
      "Iteration   0 | Train Loss  0.1908 | Classifier Accuracy 90.62\n",
      "Iteration  50 | Train Loss  0.0110 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0399 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0274 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0498 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0172 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.2601 | Classifier Accuracy 90.62\n",
      "Iteration 350 | Train Loss  0.0115 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0287 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0340 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0697 | Accuracy 97.87 | F1-Score 0.9560\n",
      "Valid Loss Mean 0.6780 | Accuracy 86.48 | F1-Score 0.7519\n",
      "\n",
      " ====================== epoch 8 ======================\n",
      "Iteration   0 | Train Loss  0.0962 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0140 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.1366 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0162 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0025 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0293 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1573 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.0103 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.1030 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0065 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0702 | Accuracy 97.73 | F1-Score 0.9523\n",
      "Valid Loss Mean 0.7547 | Accuracy 85.92 | F1-Score 0.7468\n",
      "\n",
      " ====================== epoch 9 ======================\n",
      "Iteration   0 | Train Loss  0.1408 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.3055 | Classifier Accuracy 90.62\n",
      "Iteration 100 | Train Loss  0.0334 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0053 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0683 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0065 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0881 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0971 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0077 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0112 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0749 | Accuracy 97.61 | F1-Score 0.9511\n",
      "Valid Loss Mean 0.8211 | Accuracy 85.24 | F1-Score 0.7469\n",
      "\n",
      " ====================== epoch 10 ======================\n",
      "Iteration   0 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0342 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0027 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0629 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.1990 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.4092 | Classifier Accuracy 87.50\n",
      "Iteration 300 | Train Loss  0.3163 | Classifier Accuracy 87.50\n",
      "Iteration 350 | Train Loss  0.1005 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0157 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0624 | Accuracy 97.98 | F1-Score 0.9599\n",
      "Valid Loss Mean 1.0353 | Accuracy 78.70 | F1-Score 0.6659\n",
      "\n",
      " ====================== epoch 11 ======================\n",
      "Iteration   0 | Train Loss  0.0105 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.1017 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0076 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0003 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0583 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0823 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.0025 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0099 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0148 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0121 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0620 | Accuracy 98.19 | F1-Score 0.9606\n",
      "Valid Loss Mean 0.8260 | Accuracy 84.06 | F1-Score 0.7308\n",
      "\n",
      " ====================== epoch 12 ======================\n",
      "Iteration   0 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0446 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.1214 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0516 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0027 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0049 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0080 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0072 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0133 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0107 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0477 | Accuracy 98.59 | F1-Score 0.9723\n",
      "Valid Loss Mean 0.7686 | Accuracy 82.64 | F1-Score 0.7104\n",
      "\n",
      "EARLY STOPPING!!\n",
      " ---------------------- Fold 2 --------------------------------------------\n",
      " ====================== epoch 1 ======================\n",
      "Iteration   0 | Train Loss  4.2832 | Classifier Accuracy 6.25\n",
      "Iteration  50 | Train Loss  0.9091 | Classifier Accuracy 75.00\n",
      "Iteration 100 | Train Loss  0.5453 | Classifier Accuracy 84.38\n",
      "Iteration 150 | Train Loss  0.3590 | Classifier Accuracy 81.25\n",
      "Iteration 200 | Train Loss  0.1619 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.2670 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.4664 | Classifier Accuracy 87.50\n",
      "Iteration 350 | Train Loss  0.4145 | Classifier Accuracy 81.25\n",
      "Iteration 400 | Train Loss  0.1399 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1006 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 18 s\n",
      "Train Loss Mean 0.6409 | Accuracy 80.33 | F1-Score 0.6764\n",
      "Valid Loss Mean 0.6618 | Accuracy 82.46 | F1-Score 0.7113\n",
      "\n",
      " ====================== epoch 2 ======================\n",
      "Iteration   0 | Train Loss  0.0479 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0598 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.1775 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.1077 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.2223 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.3566 | Classifier Accuracy 90.62\n",
      "Iteration 300 | Train Loss  0.3716 | Classifier Accuracy 87.50\n",
      "Iteration 350 | Train Loss  0.0566 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0614 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1020 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1795 | Accuracy 94.23 | F1-Score 0.8850\n",
      "Valid Loss Mean 0.8797 | Accuracy 83.30 | F1-Score 0.7033\n",
      "\n",
      " ====================== epoch 3 ======================\n",
      "Iteration   0 | Train Loss  0.1041 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.0871 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.1392 | Classifier Accuracy 90.62\n",
      "Iteration 150 | Train Loss  0.1589 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0520 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.4194 | Classifier Accuracy 87.50\n",
      "Iteration 300 | Train Loss  0.1444 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.0348 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.3257 | Classifier Accuracy 90.62\n",
      "Iteration 450 | Train Loss  0.0098 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1348 | Accuracy 95.73 | F1-Score 0.9154\n",
      "Valid Loss Mean 0.8172 | Accuracy 85.66 | F1-Score 0.7372\n",
      "\n",
      " ====================== epoch 4 ======================\n",
      "Iteration   0 | Train Loss  0.0130 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0229 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0102 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0475 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0580 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0338 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1739 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.1313 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.1256 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0478 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.1109 | Accuracy 96.46 | F1-Score 0.9265\n",
      "Valid Loss Mean 0.8519 | Accuracy 84.95 | F1-Score 0.7199\n",
      "\n",
      " ====================== epoch 5 ======================\n",
      "Iteration   0 | Train Loss  0.0140 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0145 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0210 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0979 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.1364 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.1351 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1996 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.1394 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0178 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0313 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1055 | Accuracy 96.74 | F1-Score 0.9322\n",
      "Valid Loss Mean 1.0319 | Accuracy 82.35 | F1-Score 0.7016\n",
      "\n",
      " ====================== epoch 6 ======================\n",
      "Iteration   0 | Train Loss  0.1325 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.0050 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0232 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0995 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0586 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0067 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.3345 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.3137 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.1481 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0162 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0930 | Accuracy 97.06 | F1-Score 0.9430\n",
      "Valid Loss Mean 0.9699 | Accuracy 82.38 | F1-Score 0.6779\n",
      "\n",
      " ====================== epoch 7 ======================\n",
      "Iteration   0 | Train Loss  0.0034 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0506 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0226 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1129 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0084 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0160 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.1973 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0512 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0177 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0008 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0746 | Accuracy 97.65 | F1-Score 0.9531\n",
      "Valid Loss Mean 1.0160 | Accuracy 83.35 | F1-Score 0.7092\n",
      "\n",
      " ====================== epoch 8 ======================\n",
      "Iteration   0 | Train Loss  0.0729 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0073 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0667 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0681 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0629 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0076 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0306 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0382 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0135 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0571 | Accuracy 98.23 | F1-Score 0.9655\n",
      "Valid Loss Mean 1.2246 | Accuracy 81.43 | F1-Score 0.6769\n",
      "\n",
      "EARLY STOPPING!!\n",
      " ---------------------- Fold 3 --------------------------------------------\n",
      " ====================== epoch 1 ======================\n",
      "Iteration   0 | Train Loss  3.3727 | Classifier Accuracy 6.25\n",
      "Iteration  50 | Train Loss  1.1029 | Classifier Accuracy 59.38\n",
      "Iteration 100 | Train Loss  0.8538 | Classifier Accuracy 78.12\n",
      "Iteration 150 | Train Loss  0.5680 | Classifier Accuracy 81.25\n",
      "Iteration 200 | Train Loss  0.7613 | Classifier Accuracy 78.12\n",
      "Iteration 250 | Train Loss  0.5313 | Classifier Accuracy 87.50\n",
      "Iteration 300 | Train Loss  0.2397 | Classifier Accuracy 90.62\n",
      "Iteration 350 | Train Loss  0.1417 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.1209 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.2646 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 19 s\n",
      "Train Loss Mean 0.6221 | Accuracy 80.88 | F1-Score 0.6882\n",
      "Valid Loss Mean 0.7126 | Accuracy 80.62 | F1-Score 0.6592\n",
      "\n",
      " ====================== epoch 2 ======================\n",
      "Iteration   0 | Train Loss  0.2475 | Classifier Accuracy 87.50\n",
      "Iteration  50 | Train Loss  0.2959 | Classifier Accuracy 87.50\n",
      "Iteration 100 | Train Loss  0.1713 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.1907 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.3069 | Classifier Accuracy 90.62\n",
      "Iteration 250 | Train Loss  0.5096 | Classifier Accuracy 87.50\n",
      "Iteration 300 | Train Loss  0.0271 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.1372 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.1472 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.1806 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1839 | Accuracy 94.15 | F1-Score 0.8815\n",
      "Valid Loss Mean 1.2234 | Accuracy 73.63 | F1-Score 0.5669\n",
      "\n",
      " ====================== epoch 3 ======================\n",
      "Iteration   0 | Train Loss  0.2341 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.0303 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0113 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1965 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.2757 | Classifier Accuracy 90.62\n",
      "Iteration 250 | Train Loss  0.0545 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.1574 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.2392 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.1657 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0834 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1496 | Accuracy 95.16 | F1-Score 0.9020\n",
      "Valid Loss Mean 0.9627 | Accuracy 80.30 | F1-Score 0.6709\n",
      "\n",
      " ====================== epoch 4 ======================\n",
      "Iteration   0 | Train Loss  0.0227 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0116 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0860 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0116 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.1878 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.2111 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.4097 | Classifier Accuracy 87.50\n",
      "Iteration 350 | Train Loss  0.1496 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.0190 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.3463 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.1207 | Accuracy 96.12 | F1-Score 0.9244\n",
      "Valid Loss Mean 1.2611 | Accuracy 76.63 | F1-Score 0.6367\n",
      "\n",
      " ====================== epoch 5 ======================\n",
      "Iteration   0 | Train Loss  0.0030 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0535 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0099 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0213 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0982 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0873 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0782 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0262 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0747 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0567 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0946 | Accuracy 96.93 | F1-Score 0.9387\n",
      "Valid Loss Mean 1.6648 | Accuracy 73.06 | F1-Score 0.6065\n",
      "\n",
      " ====================== epoch 6 ======================\n",
      "Iteration   0 | Train Loss  0.0926 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0822 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0089 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0101 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0104 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0159 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0375 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0166 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0127 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0090 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0842 | Accuracy 97.43 | F1-Score 0.9517\n",
      "Valid Loss Mean 1.1224 | Accuracy 80.54 | F1-Score 0.6406\n",
      "\n",
      " ====================== epoch 7 ======================\n",
      "Iteration   0 | Train Loss  0.1593 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.0279 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0445 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1073 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.0278 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.1273 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0195 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.4692 | Classifier Accuracy 87.50\n",
      "Iteration 400 | Train Loss  0.2265 | Classifier Accuracy 90.62\n",
      "Iteration 450 | Train Loss  0.0260 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0933 | Accuracy 97.09 | F1-Score 0.9424\n",
      "Valid Loss Mean 1.0251 | Accuracy 78.31 | F1-Score 0.6460\n",
      "\n",
      " ====================== epoch 8 ======================\n",
      "Iteration   0 | Train Loss  0.0902 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.0285 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0152 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1400 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.0220 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0664 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0267 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.1012 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0149 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0279 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0849 | Accuracy 97.21 | F1-Score 0.9446\n",
      "Valid Loss Mean 1.0351 | Accuracy 80.88 | F1-Score 0.6723\n",
      "\n",
      " ====================== epoch 9 ======================\n",
      "Iteration   0 | Train Loss  0.0052 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0900 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0013 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0233 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0082 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0088 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0132 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0059 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.1209 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0644 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0479 | Accuracy 98.51 | F1-Score 0.9691\n",
      "Valid Loss Mean 1.0831 | Accuracy 79.25 | F1-Score 0.6488\n",
      "\n",
      " ====================== epoch 10 ======================\n",
      "Iteration   0 | Train Loss  0.0089 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.1053 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0516 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0056 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0163 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.2407 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0150 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0423 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0559 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0253 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0666 | Accuracy 97.85 | F1-Score 0.9564\n",
      "Valid Loss Mean 1.0266 | Accuracy 80.15 | F1-Score 0.6548\n",
      "\n",
      " ====================== epoch 11 ======================\n",
      "Iteration   0 | Train Loss  0.0193 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0302 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0918 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.2658 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0129 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0044 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0324 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.2735 | Classifier Accuracy 90.62\n",
      "Iteration 400 | Train Loss  0.0807 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0085 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0500 | Accuracy 98.44 | F1-Score 0.9718\n",
      "Valid Loss Mean 1.0957 | Accuracy 83.90 | F1-Score 0.6858\n",
      "\n",
      " ====================== epoch 12 ======================\n",
      "Iteration   0 | Train Loss  0.0047 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0077 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0013 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1211 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0390 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0571 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1078 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0262 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0145 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0486 | Accuracy 98.47 | F1-Score 0.9686\n",
      "Valid Loss Mean 1.0246 | Accuracy 81.28 | F1-Score 0.6797\n",
      "\n",
      " ====================== epoch 13 ======================\n",
      "Iteration   0 | Train Loss  0.0256 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0044 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0914 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0454 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0006 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0151 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0048 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0303 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.1436 | Classifier Accuracy 90.62\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0351 | Accuracy 98.84 | F1-Score 0.9762\n",
      "Valid Loss Mean 1.1985 | Accuracy 79.86 | F1-Score 0.6733\n",
      "\n",
      " ====================== epoch 14 ======================\n",
      "Iteration   0 | Train Loss  0.0479 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0162 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0071 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0013 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0049 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0391 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.0185 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0037 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0256 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0121 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0417 | Accuracy 98.78 | F1-Score 0.9759\n",
      "Valid Loss Mean 1.2334 | Accuracy 81.70 | F1-Score 0.6898\n",
      "\n",
      " ====================== epoch 15 ======================\n",
      "Iteration   0 | Train Loss  0.0686 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0046 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0023 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1991 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0106 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0089 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0021 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0443 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0197 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0398 | Accuracy 98.74 | F1-Score 0.9769\n",
      "Valid Loss Mean 1.2407 | Accuracy 80.49 | F1-Score 0.6720\n",
      "\n",
      " ====================== epoch 16 ======================\n",
      "Iteration   0 | Train Loss  0.0032 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0243 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.2830 | Classifier Accuracy 93.75\n",
      "Iteration 150 | Train Loss  0.0188 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0012 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0456 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.0822 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0004 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0709 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0281 | Accuracy 99.10 | F1-Score 0.9790\n",
      "Valid Loss Mean 1.4452 | Accuracy 77.52 | F1-Score 0.6440\n",
      "\n",
      " ====================== epoch 17 ======================\n",
      "Iteration   0 | Train Loss  0.0004 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0073 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0024 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.1010 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.0620 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0074 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0112 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0075 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0150 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0390 | Accuracy 98.86 | F1-Score 0.9773\n",
      "Valid Loss Mean 1.2987 | Accuracy 81.64 | F1-Score 0.6984\n",
      "\n",
      " ====================== epoch 18 ======================\n",
      "Iteration   0 | Train Loss  0.0003 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0472 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0015 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0029 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0562 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.1402 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.2512 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.1550 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0330 | Accuracy 99.00 | F1-Score 0.9799\n",
      "Valid Loss Mean 0.9413 | Accuracy 81.96 | F1-Score 0.6935\n",
      "\n",
      " ====================== epoch 19 ======================\n",
      "Iteration   0 | Train Loss  0.0141 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0112 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0017 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0005 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0039 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0146 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.2053 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0937 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0020 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 24 s\n",
      "Train Loss Mean 0.0261 | Accuracy 99.14 | F1-Score 0.9825\n",
      "Valid Loss Mean 1.4248 | Accuracy 76.08 | F1-Score 0.6269\n",
      "\n",
      " ====================== epoch 20 ======================\n",
      "Iteration   0 | Train Loss  0.0011 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0052 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0624 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0059 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0005 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0002 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0001 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1178 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0099 | Accuracy 99.68 | F1-Score 0.9931\n",
      "Valid Loss Mean 1.5685 | Accuracy 80.70 | F1-Score 0.6804\n",
      "\n",
      " ====================== epoch 21 ======================\n",
      "Iteration   0 | Train Loss  0.0692 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0551 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0001 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0000 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0000 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0002 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0016 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0007 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0207 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1679 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0110 | Accuracy 99.63 | F1-Score 0.9915\n",
      "Valid Loss Mean 1.4669 | Accuracy 80.41 | F1-Score 0.6631\n",
      "\n",
      " ====================== epoch 22 ======================\n",
      "Iteration   0 | Train Loss  0.0542 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0135 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0052 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0058 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.1397 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0120 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0026 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0029 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0007 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0343 | Accuracy 98.85 | F1-Score 0.9772\n",
      "Valid Loss Mean 1.0793 | Accuracy 81.59 | F1-Score 0.6900\n",
      "\n",
      "EARLY STOPPING!!\n",
      " ---------------------- Fold 4 --------------------------------------------\n",
      " ====================== epoch 1 ======================\n",
      "Iteration   0 | Train Loss  4.3541 | Classifier Accuracy 9.38\n",
      "Iteration  50 | Train Loss  1.2520 | Classifier Accuracy 65.62\n",
      "Iteration 100 | Train Loss  0.6727 | Classifier Accuracy 87.50\n",
      "Iteration 150 | Train Loss  0.6543 | Classifier Accuracy 81.25\n",
      "Iteration 200 | Train Loss  0.5253 | Classifier Accuracy 81.25\n",
      "Iteration 250 | Train Loss  0.5683 | Classifier Accuracy 81.25\n",
      "Iteration 300 | Train Loss  0.5347 | Classifier Accuracy 81.25\n",
      "Iteration 350 | Train Loss  0.6265 | Classifier Accuracy 78.12\n",
      "Iteration 400 | Train Loss  0.1423 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.3081 | Classifier Accuracy 84.38\n",
      "\n",
      "[Summary] Elapsed time : 1 m 19 s\n",
      "Train Loss Mean 0.6268 | Accuracy 81.10 | F1-Score 0.6993\n",
      "Valid Loss Mean 1.2657 | Accuracy 66.39 | F1-Score 0.5243\n",
      "\n",
      " ====================== epoch 2 ======================\n",
      "Iteration   0 | Train Loss  0.3128 | Classifier Accuracy 87.50\n",
      "Iteration  50 | Train Loss  0.0914 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.1519 | Classifier Accuracy 93.75\n",
      "Iteration 150 | Train Loss  0.0985 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.4331 | Classifier Accuracy 87.50\n",
      "Iteration 250 | Train Loss  0.1433 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1677 | Classifier Accuracy 90.62\n",
      "Iteration 350 | Train Loss  0.2791 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0640 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1139 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1795 | Accuracy 94.17 | F1-Score 0.8803\n",
      "Valid Loss Mean 0.9420 | Accuracy 77.23 | F1-Score 0.6423\n",
      "\n",
      " ====================== epoch 3 ======================\n",
      "Iteration   0 | Train Loss  0.0280 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.2850 | Classifier Accuracy 90.62\n",
      "Iteration 100 | Train Loss  0.1451 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0589 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.2665 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.1961 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.1911 | Classifier Accuracy 90.62\n",
      "Iteration 350 | Train Loss  0.0302 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0385 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0665 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 27 s\n",
      "Train Loss Mean 0.1271 | Accuracy 96.04 | F1-Score 0.9226\n",
      "Valid Loss Mean 1.3348 | Accuracy 70.27 | F1-Score 0.5438\n",
      "\n",
      " ====================== epoch 4 ======================\n",
      "Iteration   0 | Train Loss  0.1808 | Classifier Accuracy 90.62\n",
      "Iteration  50 | Train Loss  0.0079 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0226 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0650 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.3079 | Classifier Accuracy 90.62\n",
      "Iteration 250 | Train Loss  0.0766 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.2187 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.0335 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.1031 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0152 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1218 | Accuracy 96.16 | F1-Score 0.9217\n",
      "Valid Loss Mean 1.2576 | Accuracy 73.14 | F1-Score 0.5723\n",
      "\n",
      " ====================== epoch 5 ======================\n",
      "Iteration   0 | Train Loss  0.0161 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.1403 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0182 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0035 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0095 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0712 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0515 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.1359 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.0396 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1334 | Classifier Accuracy 90.62\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1024 | Accuracy 96.78 | F1-Score 0.9346\n",
      "Valid Loss Mean 1.2348 | Accuracy 73.21 | F1-Score 0.5864\n",
      "\n",
      " ====================== epoch 6 ======================\n",
      "Iteration   0 | Train Loss  0.0112 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.1198 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0079 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0204 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0349 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0350 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0033 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.3355 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.1033 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.1696 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0847 | Accuracy 97.32 | F1-Score 0.9441\n",
      "Valid Loss Mean 1.2444 | Accuracy 75.68 | F1-Score 0.5949\n",
      "\n",
      " ====================== epoch 7 ======================\n",
      "Iteration   0 | Train Loss  0.0129 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0320 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0584 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0138 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0454 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0515 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.3300 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.0109 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0347 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1105 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0917 | Accuracy 97.05 | F1-Score 0.9398\n",
      "Valid Loss Mean 1.2935 | Accuracy 72.95 | F1-Score 0.6208\n",
      "\n",
      "EARLY STOPPING!!\n",
      " ---------------------- Fold 5 --------------------------------------------\n",
      " ====================== epoch 1 ======================\n",
      "Iteration   0 | Train Loss  4.6005 | Classifier Accuracy 3.12\n",
      "Iteration  50 | Train Loss  1.1868 | Classifier Accuracy 62.50\n",
      "Iteration 100 | Train Loss  0.8398 | Classifier Accuracy 75.00\n",
      "Iteration 150 | Train Loss  0.2962 | Classifier Accuracy 87.50\n",
      "Iteration 200 | Train Loss  0.2566 | Classifier Accuracy 87.50\n",
      "Iteration 250 | Train Loss  0.2524 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.5953 | Classifier Accuracy 84.38\n",
      "Iteration 350 | Train Loss  0.2076 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.1789 | Classifier Accuracy 87.50\n",
      "Iteration 450 | Train Loss  0.1302 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 19 s\n",
      "Train Loss Mean 0.6127 | Accuracy 81.61 | F1-Score 0.6983\n",
      "Valid Loss Mean 1.4497 | Accuracy 68.15 | F1-Score 0.5464\n",
      "\n",
      " ====================== epoch 2 ======================\n",
      "Iteration   0 | Train Loss  0.1564 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.1545 | Classifier Accuracy 90.62\n",
      "Iteration 100 | Train Loss  0.1137 | Classifier Accuracy 93.75\n",
      "Iteration 150 | Train Loss  0.2175 | Classifier Accuracy 90.62\n",
      "Iteration 200 | Train Loss  0.2984 | Classifier Accuracy 90.62\n",
      "Iteration 250 | Train Loss  0.0798 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1581 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.5876 | Classifier Accuracy 78.12\n",
      "Iteration 400 | Train Loss  0.1961 | Classifier Accuracy 87.50\n",
      "Iteration 450 | Train Loss  0.0455 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1746 | Accuracy 94.55 | F1-Score 0.8860\n",
      "Valid Loss Mean 1.1432 | Accuracy 75.05 | F1-Score 0.6071\n",
      "\n",
      " ====================== epoch 3 ======================\n",
      "Iteration   0 | Train Loss  0.1329 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0836 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0263 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1425 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.1320 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.1927 | Classifier Accuracy 93.75\n",
      "Iteration 300 | Train Loss  0.0293 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0169 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.2150 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.1257 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1305 | Accuracy 96.02 | F1-Score 0.9192\n",
      "Valid Loss Mean 1.2643 | Accuracy 75.34 | F1-Score 0.6160\n",
      "\n",
      " ====================== epoch 4 ======================\n",
      "Iteration   0 | Train Loss  0.0101 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.1717 | Classifier Accuracy 90.62\n",
      "Iteration 100 | Train Loss  0.0162 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1844 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.0879 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.2778 | Classifier Accuracy 90.62\n",
      "Iteration 300 | Train Loss  0.2921 | Classifier Accuracy 90.62\n",
      "Iteration 350 | Train Loss  0.0483 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0362 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0075 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1094 | Accuracy 96.43 | F1-Score 0.9272\n",
      "Valid Loss Mean 2.0514 | Accuracy 65.91 | F1-Score 0.5526\n",
      "\n",
      " ====================== epoch 5 ======================\n",
      "Iteration   0 | Train Loss  0.0204 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.2045 | Classifier Accuracy 93.75\n",
      "Iteration 100 | Train Loss  0.0654 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.1433 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0019 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0489 | Classifier Accuracy 96.88\n",
      "Iteration 300 | Train Loss  0.1400 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.4923 | Classifier Accuracy 87.50\n",
      "Iteration 400 | Train Loss  0.1583 | Classifier Accuracy 96.88\n",
      "Iteration 450 | Train Loss  0.0922 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.1035 | Accuracy 96.73 | F1-Score 0.9335\n",
      "Valid Loss Mean 1.2452 | Accuracy 75.21 | F1-Score 0.6074\n",
      "\n",
      " ====================== epoch 6 ======================\n",
      "Iteration   0 | Train Loss  0.0053 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0245 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0682 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.2010 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.4088 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.0059 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0279 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.1134 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.1351 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0112 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0739 | Accuracy 97.67 | F1-Score 0.9526\n",
      "Valid Loss Mean 1.4173 | Accuracy 77.91 | F1-Score 0.6734\n",
      "\n",
      " ====================== epoch 7 ======================\n",
      "Iteration   0 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0346 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.0037 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.1166 | Classifier Accuracy 93.75\n",
      "Iteration 200 | Train Loss  0.0727 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.3037 | Classifier Accuracy 87.50\n",
      "Iteration 300 | Train Loss  0.0264 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.1104 | Classifier Accuracy 93.75\n",
      "Iteration 400 | Train Loss  0.0203 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0694 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0706 | Accuracy 97.80 | F1-Score 0.9552\n",
      "Valid Loss Mean 2.0304 | Accuracy 67.33 | F1-Score 0.5533\n",
      "\n",
      " ====================== epoch 8 ======================\n",
      "Iteration   0 | Train Loss  0.2159 | Classifier Accuracy 93.75\n",
      "Iteration  50 | Train Loss  0.2028 | Classifier Accuracy 96.88\n",
      "Iteration 100 | Train Loss  0.5165 | Classifier Accuracy 87.50\n",
      "Iteration 150 | Train Loss  0.0054 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.3671 | Classifier Accuracy 96.88\n",
      "Iteration 250 | Train Loss  0.0181 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0044 | Classifier Accuracy 100.00\n",
      "Iteration 350 | Train Loss  0.0313 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.1307 | Classifier Accuracy 93.75\n",
      "Iteration 450 | Train Loss  0.0035 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 26 s\n",
      "Train Loss Mean 0.0636 | Accuracy 98.07 | F1-Score 0.9648\n",
      "Valid Loss Mean 1.4454 | Accuracy 75.55 | F1-Score 0.6331\n",
      "\n",
      " ====================== epoch 9 ======================\n",
      "Iteration   0 | Train Loss  0.0045 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0153 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0476 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0394 | Classifier Accuracy 100.00\n",
      "Iteration 200 | Train Loss  0.0030 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0227 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.1098 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0487 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0081 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1828 | Classifier Accuracy 93.75\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0623 | Accuracy 97.98 | F1-Score 0.9567\n",
      "Valid Loss Mean 1.5921 | Accuracy 76.39 | F1-Score 0.6287\n",
      "\n",
      " ====================== epoch 10 ======================\n",
      "Iteration   0 | Train Loss  0.0028 | Classifier Accuracy 100.00\n",
      "Iteration  50 | Train Loss  0.0031 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0058 | Classifier Accuracy 100.00\n",
      "Iteration 150 | Train Loss  0.0922 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.1279 | Classifier Accuracy 93.75\n",
      "Iteration 250 | Train Loss  0.0126 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.0720 | Classifier Accuracy 96.88\n",
      "Iteration 350 | Train Loss  0.0076 | Classifier Accuracy 100.00\n",
      "Iteration 400 | Train Loss  0.0237 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.1176 | Classifier Accuracy 96.88\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0688 | Accuracy 97.81 | F1-Score 0.9562\n",
      "Valid Loss Mean 1.5760 | Accuracy 77.68 | F1-Score 0.6387\n",
      "\n",
      " ====================== epoch 11 ======================\n",
      "Iteration   0 | Train Loss  0.0359 | Classifier Accuracy 96.88\n",
      "Iteration  50 | Train Loss  0.0126 | Classifier Accuracy 100.00\n",
      "Iteration 100 | Train Loss  0.0323 | Classifier Accuracy 96.88\n",
      "Iteration 150 | Train Loss  0.0836 | Classifier Accuracy 96.88\n",
      "Iteration 200 | Train Loss  0.0010 | Classifier Accuracy 100.00\n",
      "Iteration 250 | Train Loss  0.0009 | Classifier Accuracy 100.00\n",
      "Iteration 300 | Train Loss  0.3950 | Classifier Accuracy 93.75\n",
      "Iteration 350 | Train Loss  0.0557 | Classifier Accuracy 96.88\n",
      "Iteration 400 | Train Loss  0.0046 | Classifier Accuracy 100.00\n",
      "Iteration 450 | Train Loss  0.0025 | Classifier Accuracy 100.00\n",
      "\n",
      "[Summary] Elapsed time : 1 m 25 s\n",
      "Train Loss Mean 0.0465 | Accuracy 98.53 | F1-Score 0.9674\n",
      "Valid Loss Mean 2.1927 | Accuracy 70.75 | F1-Score 0.5980\n",
      "\n",
      "EARLY STOPPING!!\n"
     ]
    }
   ],
   "source": [
    "NUM_FINETUNE_CLASSES = 18\n",
    "\n",
    "num_epochs = 30\n",
    "EARLY_STOPPING_EPOCH = 5\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=False)\n",
    "\n",
    "best_models = {}\n",
    "fold_results = {}\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(labeled_df, labeled_df['label'])):\n",
    "    print(f' ---------------------- Fold %d --------------------------------------------' % (fold+1) )\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train = labeled_df.iloc[train_ids]\n",
    "    valid = labeled_df.iloc[test_ids]\n",
    "    \n",
    "    train_data = TrainDataset(trainimage_dir, train, transform)\n",
    "    valid_data = TrainDataset(trainimage_dir, valid, transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "\n",
    "    # Create model\n",
    "    model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=NUM_FINETUNE_CLASSES)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.RAdam(model.parameters(), lr=learning_rate, betas=betas, weight_decay=weight_decay)\n",
    "    lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_max)\n",
    "\n",
    "    # early stopping\n",
    "    valid_early_stop = 0\n",
    "    valid_best_f1score = 0.0\n",
    "    since = time.time()\n",
    "\n",
    "    for e in range(num_epochs) :\n",
    "        print(f' ====================== epoch %d ======================' % (e+1) )\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        train_epoch_f1 = 0\n",
    "        n_iter = 0\n",
    "        train_loss_list = []\n",
    "        train_acc_list = []\n",
    "        for i, (images, targets) in enumerate(train_loader) : \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            scores = model(images)\n",
    "            _, preds = scores.max(dim=1)\n",
    "\n",
    "            loss = F.cross_entropy(scores, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            correct = sum(targets == preds).cpu()\n",
    "            acc=(correct/images.shape[0] * 100)\n",
    "            train_epoch_f1 += f1_score(preds.cpu().numpy(), targets.cpu().numpy(), average='macro')\n",
    "            n_iter += 1\n",
    "\n",
    "            train_loss_list.append(loss)\n",
    "            train_acc_list.append(acc)\n",
    "\n",
    "            if i % 50 == 0 :\n",
    "                print(f'Iteration %3.d | Train Loss  %.4f | Classifier Accuracy %2.2f' % (i, loss, acc))\n",
    "\n",
    "        train_mean_loss = np.mean(train_loss_list, dtype=\"float64\")\n",
    "        train_mean_acc = np.mean(train_acc_list, dtype=\"float64\")\n",
    "\n",
    "        train_epoch_f1 = train_epoch_f1/n_iter\n",
    "\n",
    "        epoch_time = time.time() - since\n",
    "        since = time.time()\n",
    "\n",
    "        print('')\n",
    "        print(f'[Summary] Elapsed time : %.0f m %.0f s' % (epoch_time // 60, epoch_time % 60))\n",
    "        print(f'Train Loss Mean %.4f | Accuracy %2.2f | F1-Score %2.4f' % (train_mean_loss, train_mean_acc, train_epoch_f1) )\n",
    "\n",
    "        # validation \n",
    "        model.eval()\n",
    "        valid_epoch_f1 = 0\n",
    "        n_iter = 0\n",
    "        valid_loss_list = []\n",
    "        valid_acc_list = []\n",
    "        for i, (images, targets) in enumerate(valid_loader) : \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                scores = model(images)\n",
    "                loss = F.cross_entropy(scores, targets)\n",
    "                _, preds = scores.max(dim=1)\n",
    "                valid_epoch_f1 += f1_score(preds.cpu().numpy(), targets.cpu().numpy(), average='macro')\n",
    "                n_iter += 1\n",
    "\n",
    "            correct = sum(targets == preds).cpu()\n",
    "            acc=(correct/images.shape[0] * 100)\n",
    "\n",
    "            valid_loss_list.append(loss)\n",
    "            valid_acc_list.append(acc)\n",
    "\n",
    "        valid_mean_loss = np.mean(valid_loss_list, dtype=\"float64\")\n",
    "        valid_mean_acc = np.mean(valid_acc_list, dtype=\"float64\")\n",
    "\n",
    "        valid_epoch_f1 = valid_epoch_f1/n_iter\n",
    "\n",
    "        print(f'Valid Loss Mean %.4f | Accuracy %2.2f | F1-Score %2.4f' % (valid_mean_loss, valid_mean_acc, valid_epoch_f1) )\n",
    "        print('')\n",
    "        \n",
    "        if valid_epoch_f1 > valid_best_f1score:\n",
    "            valid_best_f1score = valid_epoch_f1\n",
    "            valid_early_stop = 0\n",
    "            # new best model save (valid 기준)\n",
    "            best_model = model\n",
    "            best_models[fold] = model\n",
    "            # 저장\n",
    "            path = './model/'\n",
    "            torch.save(best_model.state_dict(), f'{path}fold{fold}model{valid_epoch_f1:2.2f}_epoch_{e}.pth')\n",
    "            # update fold result\n",
    "            fold_results[fold] = {\"train_mean_acc\" : train_mean_acc, \n",
    "                                  \"train_mean_loss\" : train_mean_loss, \n",
    "                                  \"train_mean_f1\" : train_epoch_f1,\n",
    "                                  \"valid_mean_acc\" : valid_mean_acc, \n",
    "                                  \"valid_mean_loss\" : valid_mean_loss,\n",
    "                                  \"valid_mean_f1\" : valid_epoch_f1, \n",
    "                                  \"epoch\" : e}\n",
    "\n",
    "        else:\n",
    "            # early stopping    \n",
    "            valid_early_stop += 1\n",
    "            if valid_early_stop >= EARLY_STOPPING_EPOCH:  # patience\n",
    "                print(\"EARLY STOPPING!!\")\n",
    "                break\n",
    "\n",
    "        lr_sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "febf6ceb-2e2d-47b7-8efb-25d1ac4c5359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'train_mean_acc': 97.86601479915433,\n",
       "  'train_mean_loss': 0.06974846639497655,\n",
       "  'train_mean_f1': 0.9560253066677075,\n",
       "  'valid_mean_acc': 86.47584033613445,\n",
       "  'valid_mean_loss': 0.6780350068975397,\n",
       "  'valid_mean_f1': 0.7519317106095605,\n",
       "  'epoch': 6},\n",
       " 1: {'train_mean_acc': 95.72542283298097,\n",
       "  'train_mean_loss': 0.13484274076758618,\n",
       "  'train_mean_f1': 0.9153599883034015,\n",
       "  'valid_mean_acc': 85.66176470588235,\n",
       "  'valid_mean_loss': 0.8172177090740004,\n",
       "  'valid_mean_f1': 0.7372004563506488,\n",
       "  'epoch': 2},\n",
       " 2: {'train_mean_acc': 98.85702959830867,\n",
       "  'train_mean_loss': 0.0389673087549654,\n",
       "  'train_mean_f1': 0.977340661508729,\n",
       "  'valid_mean_acc': 81.64390756302521,\n",
       "  'valid_mean_loss': 1.298701960530852,\n",
       "  'valid_mean_f1': 0.6984060616949399,\n",
       "  'epoch': 16},\n",
       " 3: {'train_mean_acc': 94.16622621564483,\n",
       "  'train_mean_loss': 0.17950899350844782,\n",
       "  'train_mean_f1': 0.880325293434603,\n",
       "  'valid_mean_acc': 77.23214285714286,\n",
       "  'valid_mean_loss': 0.9420030536521383,\n",
       "  'valid_mean_f1': 0.6422796978691209,\n",
       "  'epoch': 1},\n",
       " 4: {'train_mean_acc': 97.67441860465117,\n",
       "  'train_mean_loss': 0.07387413787976721,\n",
       "  'train_mean_f1': 0.9526008339238297,\n",
       "  'valid_mean_acc': 77.91491596638656,\n",
       "  'valid_mean_loss': 1.4173453852158635,\n",
       "  'valid_mean_f1': 0.6733976061848488,\n",
       "  'epoch': 5}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-feelings",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00149092-ec53-4a79-8f2c-93fe8bbe1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        super(TestDataset).__init__()\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'\n",
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "testimage_dir = os.path.join(test_dir, 'images')\n",
    "\n",
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(testimage_dir, img_id) for img_id in submission.ImageID]\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_dataset = TestDataset(image_paths, test_transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "74666c89-1e68-489c-bba8-92d51ff02f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 42s, sys: 25.1 s, total: 24min 7s\n",
      "Wall time: 24min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scores_result = []\n",
    "\n",
    "for fold in range(n_splits):\n",
    "    torch.cuda.empty_cache()\n",
    "    model = best_models[fold]\n",
    "    #path = './model/'\n",
    "    #valid_mean_f1 = fold_results[fold]['valid_mean_f1']\n",
    "    #e = fold_results[fold]['epoch']\n",
    "    #mypath = f'{path}fold{fold}model{valid_mean_f1:2.2f}_epoch_{e}.pth'\n",
    "    #checkpoint = torch.load(mypath)\n",
    "    #model.load_state_dict(checkpoint)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    #predictions = []\n",
    "    score_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            scores = model(images)\n",
    "            _, preds = scores.max(dim=1)\n",
    "            \n",
    "            #predictions.extend(preds.detach().cpu().numpy())\n",
    "            score_list.extend(scores.detach().cpu().numpy())\n",
    "    scores_result.append(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "387b42f5-a02e-4458-abc9-b4153f3f5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12600, 18])\n"
     ]
    }
   ],
   "source": [
    "myresult = torch.tensor(scores_result)\n",
    "print(myresult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ab53ee4-5300-4929-932e-73a1f1f6341c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.7987,  3.9322, -2.6659, -2.9589, -5.8853, -6.7144, -4.1518,  0.8595,\n",
       "        -1.9714, -7.2456, -5.6743, -7.2373,  2.5590, 12.2278,  9.3114,  1.5150,\n",
       "         3.5597,  2.9023])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myresult[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "500f130f-2b7f-43aa-a076-386160d4b030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 12600, 18])\n"
     ]
    }
   ],
   "source": [
    "myresult = F.softmax(myresult, dim=2)\n",
    "print(myresult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b36eb70-393a-477d-9cba-459dcad1f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0391e-07, 2.3667e-04, 3.2256e-07, 2.4064e-07, 1.2896e-08, 5.6285e-09,\n",
       "        7.2999e-08, 1.0956e-05, 6.4599e-07, 3.3088e-09, 1.5925e-08, 3.3364e-09,\n",
       "        5.9946e-05, 9.4810e-01, 5.1322e-02, 2.1103e-05, 1.6306e-04, 8.4502e-05])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myresult[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "99423086-4782-43b4-a861-74fb28269a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12600, 18])\n"
     ]
    }
   ],
   "source": [
    "myresult = torch.sum(myresult, dim=0)\n",
    "print(myresult.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d765870a-e251-465f-9c90-f9532bc2230d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12600])\n"
     ]
    }
   ],
   "source": [
    "_, all_predictions = myresult.max(dim=1)\n",
    "print(all_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0fcf4c3e-845f-45ae-969a-d814fdffaa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13,  2, 13,  ...,  9,  1,  8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25129d26-f951-4691-85b8-2404a24335eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions = all_predictions.cpu().numpy()\n",
    "len(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "08602539-d228-4c17-a3f6-e7a8eac64759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({13: 546,\n",
       "         2: 474,\n",
       "         12: 472,\n",
       "         0: 2301,\n",
       "         7: 580,\n",
       "         3: 1528,\n",
       "         4: 1583,\n",
       "         6: 463,\n",
       "         1: 2632,\n",
       "         5: 433,\n",
       "         16: 352,\n",
       "         9: 310,\n",
       "         11: 55,\n",
       "         15: 304,\n",
       "         10: 373,\n",
       "         14: 94,\n",
       "         17: 37,\n",
       "         8: 63})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "verbal-sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission_efficientnet_stratifykfold.csv'), index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0973a2e-0393-4ba7-b392-4b89e054eeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
