{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import timm\n",
    "from timm.models.layers.classifier import ClassifierHead\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_dir = '/opt/ml/input/data/train'\n",
    "img_dir = f'{data_dir}/images'\n",
    "df_path = f'{data_dir}/train.csv'\n",
    "df = pd.read_csv(df_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_img_stats(img_dir, img_ids):\n",
    "    img_info = dict(heights=[], widths=[], means=[], stds=[])\n",
    "    for img_id in tqdm(img_ids):\n",
    "        for path in glob(os.path.join(img_dir, img_id, '*')):\n",
    "            img = np.array(Image.open(path))\n",
    "            h, w, _ = img.shape\n",
    "            img_info['heights'].append(h)\n",
    "            img_info['widths'].append(w)\n",
    "            img_info['means'].append(img.mean(axis=(0,1)))\n",
    "            img_info['stds'].append(img.std(axis=(0,1)))\n",
    "    return img_info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# img_info = get_img_stats(img_dir, df.path.values)\n",
    "\n",
    "# print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0) / 255.}')\n",
    "# print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0) / 255.}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "mean, std = ( 0.5601,0.5241,0.5014),(0.2332,0.2430,0.2456)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "    \"\"\"\n",
    "    train 혹은 validation의 augmentation 함수를 정의합니다. train은 데이터에 많은 변형을 주어야하지만, validation에는 최소한의 전처리만 주어져야합니다.\n",
    "    \n",
    "    Args:\n",
    "        need: 'train', 혹은 'val' 혹은 둘 다에 대한 augmentation 함수를 얻을 건지에 대한 옵션입니다.\n",
    "        img_size: Augmentation 이후 얻을 이미지 사이즈입니다.\n",
    "        mean: 이미지를 Normalize할 때 사용될 RGB 평균값입니다.\n",
    "        std: 이미지를 Normalize할 때 사용될 RGB 표준편차입니다.\n",
    "\n",
    "    Returns:\n",
    "        transformations: Augmentation 함수들이 저장된 dictionary 입니다. transformations['train']은 train 데이터에 대한 augmentation 함수가 있습니다.\n",
    "    \"\"\"\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            GaussNoise(p=0.5),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = Compose([\n",
    "            Resize(img_size[0], img_size[1]),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transformations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "### 마스크 여부, 성별, 나이를 mapping할 클래스를 생성합니다.\n",
    "\n",
    "class MaskLabels:\n",
    "    mask = 0\n",
    "    incorrect = 1\n",
    "    normal = 2\n",
    "\n",
    "class GenderLabels:\n",
    "    male = 0\n",
    "    female = 1\n",
    "\n",
    "class AgeGroup:\n",
    "    map_label = lambda x: 0 if int(x) < 30 else 1 if int(x) < 60 else 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1.jpg\": MaskLabels.mask,\n",
    "        \"mask2.jpg\": MaskLabels.mask,\n",
    "        \"mask3.jpg\": MaskLabels.mask,\n",
    "        \"mask4.jpg\": MaskLabels.mask,\n",
    "        \"mask5.jpg\": MaskLabels.mask,\n",
    "        \"incorrect_mask.jpg\": MaskLabels.incorrect,\n",
    "        \"normal.jpg\": MaskLabels.normal\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            for file_name, label in self._file_names.items():\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                if os.path.exists(img_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(label)\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    gender_label = getattr(GenderLabels, gender)\n",
    "                    age_label = AgeGroup.map_label(age)\n",
    "\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = int(mask_label) * 6 + int(gender_label) * 3 + int(age_label)\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = MaskBaseDataset(\n",
    "    img_dir=img_dir\n",
    ")\n",
    "\n",
    "# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valid_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Augmentation으로 이미지를 Normalize했기 때문에, 역으로 다시 Normalize 해주어야합니다.\n",
    "# inv_normalize = transforms.Normalize(\n",
    "#     mean=[-m / s for m, s in zip(mean, std)],\n",
    "#     std=[1 / s for s in std]\n",
    "# )\n",
    "\n",
    "# n_rows, n_cols = 4, 3\n",
    "\n",
    "# fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(16, 24))\n",
    "# for i in range(n_rows*n_cols):\n",
    "#     axes[i%n_rows][i//(n_cols+1)].imshow(inv_normalize(images[i]).permute(1, 2, 0))\n",
    "#     axes[i%n_rows][i//(n_cols+1)].set_title(f'Label: {labels[i]}', color='r')\n",
    "# plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#이제 모델링 \n",
    "\n",
    "model_name = \"res2next50\"\n",
    "model = timm.create_model('res2next50', pretrained=True)\n",
    "\n",
    "from timm.models.layers.classifier import ClassifierHead\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,model_name,pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model=timm.create_model(model_name,pretrained=True)\n",
    "        n_features=self.model.num_features\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.mask_classifier=ClassifierHead(n_features,3)\n",
    "        self.gender_classifier=ClassifierHead(n_features,2)\n",
    "        self.age_classifier=ClassifierHead(n_features,3)\n",
    "    def forward(self,x):\n",
    "        x=self.model.forward_features(x)\n",
    "        x=self.dropout(x)\n",
    "        mask=self.mask_classifier(x).view(x.size(0),3,1,1)\n",
    "        gender=self.gender_classifier(x).view(x.size(0),1,2,1)\n",
    "        age=self.age_classifier(x).view(x.size(0),1,1,3)\n",
    "        return (mask*gender*age).view(x.size(0),-1)\n",
    "        \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "initial_lr = 0.001\n",
    "num_epoch =30\n",
    "batch_size = 32\n",
    "betas = (0.9, 0.999)\n",
    "weight_decay = 1e-4\n",
    "T_max = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.optim as optim\n",
    "from novograd import NovoGrad\n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Initialize all weights using xavier uniform. \n",
    "    For more weight initialization methods, check https://pytorch.org/docs/stable/nn.init.html\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pprint as p\n",
    "net = MyModel(model_name,pretrained=True)\n",
    "initialize_weights(net)\n",
    "net.to(device)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottle2neck(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottle2neck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottle2neck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottle2neck(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottle2neck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottle2neck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottle2neck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottle2neck(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottle2neck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottle2neck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottle2neck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottle2neck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottle2neck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottle2neck(\n",
       "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottle2neck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottle2neck(\n",
       "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "        )\n",
       "        (bns): ModuleList(\n",
       "          (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (mask_classifier): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       "  (gender_classifier): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       "  (age_classifier): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Linear(in_features=2048, out_features=3, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "optimizer = NovoGrad(net.parameters(), lr=initial_lr, betas=betas, weight_decay=weight_decay)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=T_max)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "valid_early_stop = 0\n",
    "valid_best_loss = float('inf')\n",
    "EARLY_STOPPING_EPOCH = 5\n",
    "since = time.time()\n",
    "\n",
    "final_train_loss = []\n",
    "final_train_acc = []\n",
    "final_valid_loss = []\n",
    "final_valid_acc = []\n",
    "\n",
    "for e in range(num_epochs) :\n",
    "    p.pprint(f' ====================== epoch %d ======================' % (e+1) )\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    epoch_f1 = 0\n",
    "    n_iter = 0\n",
    "\n",
    "    # train\n",
    "    net.train()\n",
    "    for i, (images, targets) in enumerate(train_loader) : \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        scores = net(images)\n",
    "        \n",
    "        _, preds = scores.max(dim=1)\n",
    "\n",
    "        loss = F.cross_entropy(scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        correct = sum(targets == preds).cpu()\n",
    "        acc=(correct/images.shape[0] * 100)\n",
    "        epoch_f1 += f1_score(preds.cpu().numpy(), targets.cpu().numpy(), average='macro')\n",
    "        n_iter += 1\n",
    "\n",
    "        train_loss_list.append(loss)\n",
    "        train_acc_list.append(acc)\n",
    "\n",
    "        if i % 50 == 0 :\n",
    "            p.pprint(f'Iteration %3.d | Train Loss  %.4f | Classifier Accuracy %2.2f' % (i, loss, acc))\n",
    "\n",
    "    train_mean_loss = np.mean(train_loss_list, dtype=\"float64\")\n",
    "    train_mean_acc = np.mean(train_acc_list, dtype=\"float64\")\n",
    "\n",
    "    final_train_loss.append(train_mean_loss)\n",
    "    final_train_acc.append(train_mean_acc)\n",
    "    \n",
    "    epoch_f1 = epoch_f1/n_iter\n",
    "\n",
    "    epoch_time = time.time() - since\n",
    "    since = time.time()\n",
    "\n",
    "    p.pprint('')\n",
    "    p.pprint(f'[Summary] Elapsed time : %.0f m %.0f s' % (epoch_time // 60, epoch_time % 60))\n",
    "    p.pprint(f'Train Loss Mean %.4f | Accuracy %2.2f | F1-Score %2.4f' % (train_mean_loss, train_mean_acc, epoch_f1) )\n",
    "\n",
    "    # validation \n",
    "    net.eval()\n",
    "    epoch_f1 = 0\n",
    "    n_iter = 0\n",
    "    valid_loss_list = []\n",
    "    valid_acc_list = []\n",
    "    for i, (images, targets) in enumerate(valid_loader) : \n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            scores = net(images)  \n",
    "            loss = F.cross_entropy(scores, targets)\n",
    "            _, preds = scores.max(dim=1)\n",
    "            epoch_f1 += f1_score(preds.cpu().numpy(), targets.cpu().numpy(), average='macro')\n",
    "            n_iter += 1\n",
    "\n",
    "        correct = sum(targets == preds).cpu()\n",
    "        acc=(correct/images.shape[0] * 100)\n",
    "\n",
    "        valid_loss_list.append(loss)\n",
    "        valid_acc_list.append(acc)\n",
    "\n",
    "    val_mean_loss = np.mean(valid_loss_list, dtype=\"float64\")\n",
    "    val_mean_acc = np.mean(valid_acc_list, dtype=\"float64\")\n",
    "\n",
    "    final_valid_loss.append(val_mean_loss)\n",
    "    final_valid_acc.append(val_mean_acc)\n",
    "    \n",
    "    epoch_f1 = epoch_f1/n_iter\n",
    "    \n",
    "    p.pprint(f'Valid Loss Mean %.4f | Accuracy %2.2f | F1-Score %2.4f' % (val_mean_loss, val_mean_acc, epoch_f1) )\n",
    "    p.pprint('')\n",
    "\n",
    "    if val_mean_loss < valid_best_loss:\n",
    "        valid_best_loss = val_mean_loss\n",
    "        valid_early_stop = 0\n",
    "        # new best model save (valid 기준)\n",
    "        best_model = net\n",
    "        path = './model/'\n",
    "        torch.save(best_model.state_dict(), f'{path}model{val_mean_acc:2.2f}_epoch_{e}.pth')\n",
    "    else:\n",
    "        # early stopping    \n",
    "        valid_early_stop += 1\n",
    "        if valid_early_stop >= EARLY_STOPPING_EPOCH:\n",
    "            p.pprint(\"EARLY STOPPING!!\")\n",
    "            break\n",
    "\n",
    "    lr_sched.step()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "' ====================== epoch 1 ======================'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/opt/ml/teamrepo/kbs/code/novograd.py:69: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
      "  p.data.add_(-step_size, m)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'Iteration   0 | Train Loss  2.9299 | Classifier Accuracy 3.12'\n",
      "'Iteration  50 | Train Loss  2.6768 | Classifier Accuracy 12.50'\n",
      "'Iteration 100 | Train Loss  2.3691 | Classifier Accuracy 37.50'\n",
      "'Iteration 150 | Train Loss  2.4841 | Classifier Accuracy 28.12'\n",
      "'Iteration 200 | Train Loss  2.4899 | Classifier Accuracy 31.25'\n",
      "'Iteration 250 | Train Loss  2.4486 | Classifier Accuracy 28.12'\n",
      "'Iteration 300 | Train Loss  2.2283 | Classifier Accuracy 31.25'\n",
      "'Iteration 350 | Train Loss  2.1426 | Classifier Accuracy 34.38'\n",
      "'Iteration 400 | Train Loss  1.9329 | Classifier Accuracy 34.38'\n",
      "'Iteration 450 | Train Loss  1.7689 | Classifier Accuracy 39.29'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 12 s'\n",
      "'Train Loss Mean 2.2906 | Accuracy 28.51 | F1-Score 0.0919'\n",
      "'Valid Loss Mean 2.0327 | Accuracy 37.61 | F1-Score 0.1530'\n",
      "''\n",
      "' ====================== epoch 2 ======================'\n",
      "'Iteration   0 | Train Loss  2.0110 | Classifier Accuracy 37.50'\n",
      "'Iteration  50 | Train Loss  2.0203 | Classifier Accuracy 31.25'\n",
      "'Iteration 100 | Train Loss  2.0017 | Classifier Accuracy 28.12'\n",
      "'Iteration 150 | Train Loss  1.6669 | Classifier Accuracy 43.75'\n",
      "'Iteration 200 | Train Loss  1.9213 | Classifier Accuracy 40.62'\n",
      "'Iteration 250 | Train Loss  1.6185 | Classifier Accuracy 46.88'\n",
      "'Iteration 300 | Train Loss  1.8990 | Classifier Accuracy 31.25'\n",
      "'Iteration 350 | Train Loss  1.9397 | Classifier Accuracy 34.38'\n",
      "'Iteration 400 | Train Loss  1.7032 | Classifier Accuracy 50.00'\n",
      "'Iteration 450 | Train Loss  1.7802 | Classifier Accuracy 46.43'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 34 s'\n",
      "'Train Loss Mean 1.8448 | Accuracy 42.59 | F1-Score 0.1932'\n",
      "'Valid Loss Mean 1.8128 | Accuracy 43.79 | F1-Score 0.2177'\n",
      "''\n",
      "' ====================== epoch 3 ======================'\n",
      "'Iteration   0 | Train Loss  1.6161 | Classifier Accuracy 37.50'\n",
      "'Iteration  50 | Train Loss  1.2880 | Classifier Accuracy 65.62'\n",
      "'Iteration 100 | Train Loss  1.5576 | Classifier Accuracy 46.88'\n",
      "'Iteration 150 | Train Loss  1.7512 | Classifier Accuracy 53.12'\n",
      "'Iteration 200 | Train Loss  1.5074 | Classifier Accuracy 53.12'\n",
      "'Iteration 250 | Train Loss  1.5642 | Classifier Accuracy 46.88'\n",
      "'Iteration 300 | Train Loss  1.4908 | Classifier Accuracy 43.75'\n",
      "'Iteration 350 | Train Loss  1.7400 | Classifier Accuracy 46.88'\n",
      "'Iteration 400 | Train Loss  1.2460 | Classifier Accuracy 56.25'\n",
      "'Iteration 450 | Train Loss  1.6895 | Classifier Accuracy 42.86'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 33 s'\n",
      "'Train Loss Mean 1.6101 | Accuracy 48.46 | F1-Score 0.2626'\n",
      "'Valid Loss Mean 1.6514 | Accuracy 49.86 | F1-Score 0.2637'\n",
      "''\n",
      "' ====================== epoch 4 ======================'\n",
      "'Iteration   0 | Train Loss  1.6102 | Classifier Accuracy 50.00'\n",
      "'Iteration  50 | Train Loss  1.1664 | Classifier Accuracy 62.50'\n",
      "'Iteration 100 | Train Loss  1.3529 | Classifier Accuracy 46.88'\n",
      "'Iteration 150 | Train Loss  1.4632 | Classifier Accuracy 50.00'\n",
      "'Iteration 200 | Train Loss  2.0328 | Classifier Accuracy 37.50'\n",
      "'Iteration 250 | Train Loss  1.3234 | Classifier Accuracy 56.25'\n",
      "'Iteration 300 | Train Loss  1.7102 | Classifier Accuracy 46.88'\n",
      "'Iteration 350 | Train Loss  1.4455 | Classifier Accuracy 50.00'\n",
      "'Iteration 400 | Train Loss  0.9066 | Classifier Accuracy 68.75'\n",
      "'Iteration 450 | Train Loss  1.0469 | Classifier Accuracy 57.14'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 34 s'\n",
      "'Train Loss Mean 1.3375 | Accuracy 55.70 | F1-Score 0.3628'\n",
      "'Valid Loss Mean 1.2193 | Accuracy 59.44 | F1-Score 0.4199'\n",
      "''\n",
      "' ====================== epoch 5 ======================'\n",
      "'Iteration   0 | Train Loss  1.4437 | Classifier Accuracy 53.12'\n",
      "'Iteration  50 | Train Loss  0.8506 | Classifier Accuracy 65.62'\n",
      "'Iteration 100 | Train Loss  1.2174 | Classifier Accuracy 56.25'\n",
      "'Iteration 150 | Train Loss  1.2546 | Classifier Accuracy 62.50'\n",
      "'Iteration 200 | Train Loss  1.0570 | Classifier Accuracy 68.75'\n",
      "'Iteration 250 | Train Loss  0.7227 | Classifier Accuracy 68.75'\n",
      "'Iteration 300 | Train Loss  1.0460 | Classifier Accuracy 71.88'\n",
      "'Iteration 350 | Train Loss  1.0087 | Classifier Accuracy 59.38'\n",
      "'Iteration 400 | Train Loss  0.6115 | Classifier Accuracy 87.50'\n",
      "'Iteration 450 | Train Loss  0.8174 | Classifier Accuracy 67.86'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 33 s'\n",
      "'Train Loss Mean 1.0308 | Accuracy 65.46 | F1-Score 0.4912'\n",
      "'Valid Loss Mean 0.8778 | Accuracy 71.00 | F1-Score 0.5725'\n",
      "''\n",
      "' ====================== epoch 6 ======================'\n",
      "'Iteration   0 | Train Loss  1.1489 | Classifier Accuracy 46.88'\n",
      "'Iteration  50 | Train Loss  0.8156 | Classifier Accuracy 68.75'\n",
      "'Iteration 100 | Train Loss  0.7065 | Classifier Accuracy 78.12'\n",
      "'Iteration 150 | Train Loss  0.6949 | Classifier Accuracy 75.00'\n",
      "'Iteration 200 | Train Loss  0.5361 | Classifier Accuracy 87.50'\n",
      "'Iteration 250 | Train Loss  0.9593 | Classifier Accuracy 71.88'\n",
      "'Iteration 300 | Train Loss  0.9022 | Classifier Accuracy 71.88'\n",
      "'Iteration 350 | Train Loss  0.6084 | Classifier Accuracy 75.00'\n",
      "'Iteration 400 | Train Loss  0.9710 | Classifier Accuracy 59.38'\n",
      "'Iteration 450 | Train Loss  0.9591 | Classifier Accuracy 64.29'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 33 s'\n",
      "'Train Loss Mean 0.8278 | Accuracy 71.46 | F1-Score 0.5683'\n",
      "'Valid Loss Mean 1.0518 | Accuracy 65.62 | F1-Score 0.4940'\n",
      "''\n",
      "' ====================== epoch 7 ======================'\n",
      "'Iteration   0 | Train Loss  0.6362 | Classifier Accuracy 78.12'\n",
      "'Iteration  50 | Train Loss  1.2552 | Classifier Accuracy 71.88'\n",
      "'Iteration 100 | Train Loss  0.6921 | Classifier Accuracy 78.12'\n",
      "'Iteration 150 | Train Loss  0.6520 | Classifier Accuracy 84.38'\n",
      "'Iteration 200 | Train Loss  0.5847 | Classifier Accuracy 81.25'\n",
      "'Iteration 250 | Train Loss  0.4291 | Classifier Accuracy 81.25'\n",
      "'Iteration 300 | Train Loss  0.6237 | Classifier Accuracy 71.88'\n",
      "'Iteration 350 | Train Loss  0.6357 | Classifier Accuracy 78.12'\n",
      "'Iteration 400 | Train Loss  1.0594 | Classifier Accuracy 68.75'\n",
      "'Iteration 450 | Train Loss  0.5934 | Classifier Accuracy 85.71'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 34 s'\n",
      "'Train Loss Mean 0.7249 | Accuracy 74.91 | F1-Score 0.6165'\n",
      "'Valid Loss Mean 0.7900 | Accuracy 76.45 | F1-Score 0.6308'\n",
      "''\n",
      "' ====================== epoch 8 ======================'\n",
      "'Iteration   0 | Train Loss  0.5589 | Classifier Accuracy 84.38'\n",
      "'Iteration  50 | Train Loss  0.4607 | Classifier Accuracy 87.50'\n",
      "'Iteration 100 | Train Loss  0.3301 | Classifier Accuracy 87.50'\n",
      "'Iteration 150 | Train Loss  0.7349 | Classifier Accuracy 81.25'\n",
      "'Iteration 200 | Train Loss  1.0592 | Classifier Accuracy 65.62'\n",
      "'Iteration 250 | Train Loss  0.6215 | Classifier Accuracy 78.12'\n",
      "'Iteration 300 | Train Loss  0.5247 | Classifier Accuracy 84.38'\n",
      "'Iteration 350 | Train Loss  0.9932 | Classifier Accuracy 75.00'\n",
      "'Iteration 400 | Train Loss  0.8130 | Classifier Accuracy 65.62'\n",
      "'Iteration 450 | Train Loss  0.4899 | Classifier Accuracy 82.14'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 33 s'\n",
      "'Train Loss Mean 0.6464 | Accuracy 77.50 | F1-Score 0.6457'\n",
      "'Valid Loss Mean 1.1402 | Accuracy 64.23 | F1-Score 0.5009'\n",
      "''\n",
      "' ====================== epoch 9 ======================'\n",
      "'Iteration   0 | Train Loss  0.5997 | Classifier Accuracy 68.75'\n",
      "'Iteration  50 | Train Loss  0.7339 | Classifier Accuracy 78.12'\n",
      "'Iteration 100 | Train Loss  0.7937 | Classifier Accuracy 62.50'\n",
      "'Iteration 150 | Train Loss  0.4433 | Classifier Accuracy 84.38'\n",
      "'Iteration 200 | Train Loss  0.3596 | Classifier Accuracy 87.50'\n",
      "'Iteration 250 | Train Loss  0.5613 | Classifier Accuracy 81.25'\n",
      "'Iteration 300 | Train Loss  0.5681 | Classifier Accuracy 78.12'\n",
      "'Iteration 350 | Train Loss  0.5828 | Classifier Accuracy 68.75'\n",
      "'Iteration 400 | Train Loss  0.5504 | Classifier Accuracy 78.12'\n",
      "'Iteration 450 | Train Loss  0.2948 | Classifier Accuracy 89.29'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 33 s'\n",
      "'Train Loss Mean 0.5767 | Accuracy 80.11 | F1-Score 0.6737'\n",
      "'Valid Loss Mean 1.0798 | Accuracy 71.04 | F1-Score 0.5725'\n",
      "''\n",
      "' ====================== epoch 10 ======================'\n",
      "'Iteration   0 | Train Loss  0.4565 | Classifier Accuracy 84.38'\n",
      "'Iteration  50 | Train Loss  0.4290 | Classifier Accuracy 81.25'\n",
      "'Iteration 100 | Train Loss  0.6551 | Classifier Accuracy 75.00'\n",
      "'Iteration 150 | Train Loss  0.2197 | Classifier Accuracy 90.62'\n",
      "'Iteration 200 | Train Loss  0.6545 | Classifier Accuracy 78.12'\n",
      "'Iteration 250 | Train Loss  0.4650 | Classifier Accuracy 84.38'\n",
      "'Iteration 300 | Train Loss  0.6198 | Classifier Accuracy 81.25'\n",
      "'Iteration 350 | Train Loss  0.4495 | Classifier Accuracy 87.50'\n",
      "'Iteration 400 | Train Loss  0.2549 | Classifier Accuracy 93.75'\n",
      "'Iteration 450 | Train Loss  0.5717 | Classifier Accuracy 75.00'\n",
      "''\n",
      "'[Summary] Elapsed time : 5 m 33 s'\n",
      "'Train Loss Mean 0.5359 | Accuracy 81.49 | F1-Score 0.7013'\n",
      "'Valid Loss Mean 0.4807 | Accuracy 83.55 | F1-Score 0.7328'\n",
      "''\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        super(TestDataset).__init__()\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# 테스트 데이터셋 폴더 경로를 지정해주세요.\n",
    "test_dir = '/opt/ml/input/data/eval'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "# meta 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))\n",
    "testimage_dir = os.path.join(test_dir, 'images')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n",
    "image_paths = [os.path.join(testimage_dir, img_id) for img_id in submission.ImageID]\n",
    "transform = transforms.Compose([\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "test_dataset = TestDataset(image_paths, transform)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "best_model.eval()\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for images in test_loader:\n",
    "    with torch.no_grad():\n",
    "        images = images.to(device)\n",
    "        scores = best_model(images)\n",
    "        preds = scores.argmax(dim=-1)\n",
    "        all_predictions.extend(preds.cpu().numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from collections import Counter\n",
    "Counter(all_predictions)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({12: 11484, 15: 1044, 13: 68, 16: 4})"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv(os.path.join(test_dir, 'submission_RES2NEXT_2.csv'), index=False)\n",
    "print('test inference is done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test inference is done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "print(datetime.now(timezone('asia/seoul')).strftime('%Y-%m-%d %H:%M:%S'))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-08-26 00:21:34\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}